# Slack Topic Classification Workflow

## Overview
This directory contains everything needed to fetch Slack questions, predict their business topics, and explore the results in a Streamlit dashboard. The workflow combines semantic embeddings, centroid-based topic assignment, and clustering for subtopics.

## Contents
```
app.py                 # Streamlit dashboard (historical + live)
Training.py              # Primary training pipeline that exports centroids
model.py               # Alternate training/evaluation script
slack_helper.py        # Slack Web API + Socket Mode utilities
slack_predictor.py     # Historical fetch + topic/subtopic prediction
slack_service.py       # Live tracker used by the dashboard
topic_subtopic_model.pkl
.env                   # Slack credentials (not committed)
```

## Prerequisites
- Python 3.10+
- Slack workspace with a Socket Mode app that has:
  - App-level token (`SLACK_APP_TOKEN`)
  - Bot token (`SLACK_BOT_TOKEN`) with access to the target channel (`SLACK_CHANNEL_ID`)
- Virtual environment strongly recommended

## Setup
1. Create and activate a virtual environment:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```
2. Install dependencies inside this folder:
   ```bash
   pip install -r requirements.txt
   ```
3. Configure environment variables by creating `.env` in this directory:
   ```env
   SLACK_APP_TOKEN=xapp-1-...
   SLACK_BOT_TOKEN=xoxb-...
   SLACK_CHANNEL_ID=C0123456789
   ```

## Historical Message Fetching & Prediction
`slack_predictor.py` pulls message history from the configured Slack channel, generates embeddings with SentenceTransformers, and assigns topics/subtopics using stored centroids.

Run ad hoc:
```bash
python slack_predictor.py
```
The script returns a DataFrame aligned with `DATA_COLUMNS` used downstream by the dashboard.

## Training Pipeline
`cosine.py` is the main training script. It:
- Loads labeled CSV datasets (`csv2.csv`, `dataset.csv`)
- Builds topic centroids with semantic embeddings
- Evaluates accuracy (validation + external datasets)
- Exports `topic_subtopic_model.pkl` plus `output_topic_subtopic.csv`

Execute:
```bash
python cosine.py
```

If you prefer a lighter evaluation-only run, use `model.py`.

## Live Message Tracking
`slack_service.py` exposes `LiveTopicTracker`, which listens to Slack via Socket Mode, deduplicates new messages, embeds them, and predicts topics on the fly. The Streamlit app consumes this tracker to blend live data with historical predictions.

Start the dashboard:
```bash
streamlit run app.py
```

Within the UI you can sync history, refresh live messages, filter by topic/date, and inspect clusters.

## Data & Artifacts
- `topic_subtopic_model.pkl` stores embeddings, topics, and IDs required by predictors and the live tracker.
- `output_topic_subtopic.csv` (generated by `cosine.py`) is a ready-to-explore labeled dataset.
- CSV inputs are sensitive; keep them out of source control if they contain private content.

## Notes
- Keep `.env` private (listed in `.gitignore`).
- Regenerate the model whenever labeled data changes so live predictions stay consistent.
